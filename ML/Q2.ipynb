{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Dry_Bean_Dataset.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "      <td>13611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53048.284549</td>\n",
       "      <td>855.283459</td>\n",
       "      <td>320.141867</td>\n",
       "      <td>202.270714</td>\n",
       "      <td>1.583242</td>\n",
       "      <td>0.750895</td>\n",
       "      <td>53768.200206</td>\n",
       "      <td>253.064220</td>\n",
       "      <td>0.749733</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.873282</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.643590</td>\n",
       "      <td>0.995063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29324.095717</td>\n",
       "      <td>214.289696</td>\n",
       "      <td>85.694186</td>\n",
       "      <td>44.970091</td>\n",
       "      <td>0.246678</td>\n",
       "      <td>0.092002</td>\n",
       "      <td>29774.915817</td>\n",
       "      <td>59.177120</td>\n",
       "      <td>0.049086</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.059520</td>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.098996</td>\n",
       "      <td>0.004366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20420.000000</td>\n",
       "      <td>524.736000</td>\n",
       "      <td>183.601165</td>\n",
       "      <td>122.512653</td>\n",
       "      <td>1.024868</td>\n",
       "      <td>0.218951</td>\n",
       "      <td>20684.000000</td>\n",
       "      <td>161.243764</td>\n",
       "      <td>0.555315</td>\n",
       "      <td>0.919246</td>\n",
       "      <td>0.489618</td>\n",
       "      <td>0.640577</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.410339</td>\n",
       "      <td>0.947687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36328.000000</td>\n",
       "      <td>703.523500</td>\n",
       "      <td>253.303633</td>\n",
       "      <td>175.848170</td>\n",
       "      <td>1.432307</td>\n",
       "      <td>0.715928</td>\n",
       "      <td>36714.500000</td>\n",
       "      <td>215.068003</td>\n",
       "      <td>0.718634</td>\n",
       "      <td>0.985670</td>\n",
       "      <td>0.832096</td>\n",
       "      <td>0.762469</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.581359</td>\n",
       "      <td>0.993703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44652.000000</td>\n",
       "      <td>794.941000</td>\n",
       "      <td>296.883367</td>\n",
       "      <td>192.431733</td>\n",
       "      <td>1.551124</td>\n",
       "      <td>0.764441</td>\n",
       "      <td>45178.000000</td>\n",
       "      <td>238.438026</td>\n",
       "      <td>0.759859</td>\n",
       "      <td>0.988283</td>\n",
       "      <td>0.883157</td>\n",
       "      <td>0.801277</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.642044</td>\n",
       "      <td>0.996386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61332.000000</td>\n",
       "      <td>977.213000</td>\n",
       "      <td>376.495012</td>\n",
       "      <td>217.031741</td>\n",
       "      <td>1.707109</td>\n",
       "      <td>0.810466</td>\n",
       "      <td>62294.000000</td>\n",
       "      <td>279.446467</td>\n",
       "      <td>0.786851</td>\n",
       "      <td>0.990013</td>\n",
       "      <td>0.916869</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.696006</td>\n",
       "      <td>0.997883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>254616.000000</td>\n",
       "      <td>1985.370000</td>\n",
       "      <td>738.860153</td>\n",
       "      <td>460.198497</td>\n",
       "      <td>2.430306</td>\n",
       "      <td>0.911423</td>\n",
       "      <td>263261.000000</td>\n",
       "      <td>569.374358</td>\n",
       "      <td>0.866195</td>\n",
       "      <td>0.994677</td>\n",
       "      <td>0.990685</td>\n",
       "      <td>0.987303</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.974767</td>\n",
       "      <td>0.999733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Area     Perimeter  MajorAxisLength  MinorAxisLength  \\\n",
       "count   13611.000000  13611.000000     13611.000000     13611.000000   \n",
       "mean    53048.284549    855.283459       320.141867       202.270714   \n",
       "std     29324.095717    214.289696        85.694186        44.970091   \n",
       "min     20420.000000    524.736000       183.601165       122.512653   \n",
       "25%     36328.000000    703.523500       253.303633       175.848170   \n",
       "50%     44652.000000    794.941000       296.883367       192.431733   \n",
       "75%     61332.000000    977.213000       376.495012       217.031741   \n",
       "max    254616.000000   1985.370000       738.860153       460.198497   \n",
       "\n",
       "       AspectRation  Eccentricity     ConvexArea  EquivDiameter        Extent  \\\n",
       "count  13611.000000  13611.000000   13611.000000   13611.000000  13611.000000   \n",
       "mean       1.583242      0.750895   53768.200206     253.064220      0.749733   \n",
       "std        0.246678      0.092002   29774.915817      59.177120      0.049086   \n",
       "min        1.024868      0.218951   20684.000000     161.243764      0.555315   \n",
       "25%        1.432307      0.715928   36714.500000     215.068003      0.718634   \n",
       "50%        1.551124      0.764441   45178.000000     238.438026      0.759859   \n",
       "75%        1.707109      0.810466   62294.000000     279.446467      0.786851   \n",
       "max        2.430306      0.911423  263261.000000     569.374358      0.866195   \n",
       "\n",
       "           Solidity     roundness   Compactness  ShapeFactor1  ShapeFactor2  \\\n",
       "count  13611.000000  13611.000000  13611.000000  13611.000000  13611.000000   \n",
       "mean       0.987143      0.873282      0.799864      0.006564      0.001716   \n",
       "std        0.004660      0.059520      0.061713      0.001128      0.000596   \n",
       "min        0.919246      0.489618      0.640577      0.002778      0.000564   \n",
       "25%        0.985670      0.832096      0.762469      0.005900      0.001154   \n",
       "50%        0.988283      0.883157      0.801277      0.006645      0.001694   \n",
       "75%        0.990013      0.916869      0.834270      0.007271      0.002170   \n",
       "max        0.994677      0.990685      0.987303      0.010451      0.003665   \n",
       "\n",
       "       ShapeFactor3  ShapeFactor4  \n",
       "count  13611.000000  13611.000000  \n",
       "mean       0.643590      0.995063  \n",
       "std        0.098996      0.004366  \n",
       "min        0.410339      0.947687  \n",
       "25%        0.581359      0.993703  \n",
       "50%        0.642044      0.996386  \n",
       "75%        0.696006      0.997883  \n",
       "max        0.974767      0.999733  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83879977, -1.13966273, -1.30197615, ...,  2.39827994,\n",
       "         1.92481096,  0.83867856],\n",
       "       [-0.82726577, -1.01052862, -1.39116937, ...,  3.09747107,\n",
       "         2.69144645,  0.77114139],\n",
       "       [-0.80528652, -1.07530293, -1.24780735, ...,  2.23108594,\n",
       "         1.8401498 ,  0.91741775],\n",
       "       ...,\n",
       "       [-0.37117925, -0.44557909, -0.44700409, ...,  0.28388754,\n",
       "         0.32988743,  0.38852873],\n",
       "       [-0.37090706, -0.42481666, -0.42552883, ...,  0.22301752,\n",
       "         0.24222869,  0.03311486],\n",
       "       [-0.37049878, -0.38542487, -0.2884744 , ..., -0.13337374,\n",
       "        -0.28505378,  0.71346236]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y to 2D array with a single column\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# early stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,embedding_dims,))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary crossentropy \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2546 - loss: 1.8695 - val_accuracy: 0.4270 - val_loss: 1.7458\n",
      "Epoch 2/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3790 - loss: 1.7660 - val_accuracy: 0.4274 - val_loss: 1.7303\n",
      "Epoch 3/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4046 - loss: 1.7480 - val_accuracy: 0.4684 - val_loss: 1.6960\n",
      "Epoch 4/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4271 - loss: 1.7289 - val_accuracy: 0.5381 - val_loss: 1.6424\n",
      "Epoch 5/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4710 - loss: 1.6826 - val_accuracy: 0.5336 - val_loss: 1.6286\n",
      "Epoch 6/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5006 - loss: 1.6615 - val_accuracy: 0.5332 - val_loss: 1.6278\n",
      "Epoch 7/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5071 - loss: 1.6588 - val_accuracy: 0.5336 - val_loss: 1.6239\n",
      "Epoch 8/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5027 - loss: 1.6611 - val_accuracy: 0.5357 - val_loss: 1.6201\n",
      "Epoch 9/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5046 - loss: 1.6596 - val_accuracy: 0.5636 - val_loss: 1.6131\n",
      "Epoch 10/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5157 - loss: 1.6478 - val_accuracy: 0.5525 - val_loss: 1.6034\n",
      "Epoch 11/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5193 - loss: 1.6476 - val_accuracy: 0.5648 - val_loss: 1.6148\n",
      "Epoch 12/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5307 - loss: 1.6359 - val_accuracy: 0.5804 - val_loss: 1.5969\n",
      "Epoch 13/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5313 - loss: 1.6374 - val_accuracy: 0.5763 - val_loss: 1.5952\n",
      "Epoch 14/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5419 - loss: 1.6252 - val_accuracy: 0.5763 - val_loss: 1.5958\n",
      "Epoch 15/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5243 - loss: 1.6410 - val_accuracy: 0.5792 - val_loss: 1.5938\n",
      "Epoch 16/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5204 - loss: 1.6439 - val_accuracy: 0.5845 - val_loss: 1.5912\n",
      "Epoch 17/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5381 - loss: 1.6293 - val_accuracy: 0.5808 - val_loss: 1.5921\n",
      "Epoch 18/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5239 - loss: 1.6393 - val_accuracy: 0.5845 - val_loss: 1.5898\n",
      "Epoch 19/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5405 - loss: 1.6263 - val_accuracy: 0.5759 - val_loss: 1.5921\n",
      "Epoch 20/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5342 - loss: 1.6326 - val_accuracy: 0.5792 - val_loss: 1.5922\n",
      "Epoch 21/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5283 - loss: 1.6365 - val_accuracy: 0.5747 - val_loss: 1.5900\n",
      "Epoch 22/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5340 - loss: 1.6349 - val_accuracy: 0.5792 - val_loss: 1.5943\n",
      "Epoch 23/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5373 - loss: 1.6298 - val_accuracy: 0.5800 - val_loss: 1.5908\n",
      "Epoch 24/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5298 - loss: 1.6363 - val_accuracy: 0.5845 - val_loss: 1.5890\n",
      "Epoch 25/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5294 - loss: 1.6384 - val_accuracy: 0.5804 - val_loss: 1.5939\n",
      "Epoch 26/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5322 - loss: 1.6353 - val_accuracy: 0.5808 - val_loss: 1.5875\n",
      "Epoch 27/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5302 - loss: 1.6362 - val_accuracy: 0.5812 - val_loss: 1.5867\n",
      "Epoch 28/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5440 - loss: 1.6226 - val_accuracy: 0.5792 - val_loss: 1.5860\n",
      "Epoch 29/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5413 - loss: 1.6245 - val_accuracy: 0.5841 - val_loss: 1.5855\n",
      "Epoch 30/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5380 - loss: 1.6303 - val_accuracy: 0.5886 - val_loss: 1.5787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d21e6cff10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_loss', patience=30, mode='min', min_delta=0.0001),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 1.6242 - val_accuracy: 0.5906 - val_loss: 1.5761\n",
      "Epoch 2/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 1.6217 - val_accuracy: 0.5968 - val_loss: 1.5748\n",
      "Epoch 3/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5409 - loss: 1.6245 - val_accuracy: 0.5960 - val_loss: 1.5755\n",
      "Epoch 4/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5447 - loss: 1.6242 - val_accuracy: 0.5841 - val_loss: 1.5765\n",
      "Epoch 5/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5573 - loss: 1.6130 - val_accuracy: 0.5931 - val_loss: 1.5729\n",
      "Epoch 6/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5625 - loss: 1.6087 - val_accuracy: 0.5931 - val_loss: 1.5750\n",
      "Epoch 7/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5611 - loss: 1.6089 - val_accuracy: 0.5870 - val_loss: 1.5756\n",
      "Epoch 8/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5693 - loss: 1.5989 - val_accuracy: 0.5968 - val_loss: 1.5709\n",
      "Epoch 9/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5577 - loss: 1.6111 - val_accuracy: 0.5976 - val_loss: 1.5700\n",
      "Epoch 10/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5691 - loss: 1.6004 - val_accuracy: 0.5984 - val_loss: 1.5707\n",
      "Epoch 11/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: 1.6147 - val_accuracy: 0.5894 - val_loss: 1.5747\n",
      "Epoch 12/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5632 - loss: 1.6037 - val_accuracy: 0.5906 - val_loss: 1.5744\n",
      "Epoch 13/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5624 - loss: 1.6054 - val_accuracy: 0.5960 - val_loss: 1.5703\n",
      "Epoch 14/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5610 - loss: 1.6077 - val_accuracy: 0.5947 - val_loss: 1.5733\n",
      "Epoch 15/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5754 - loss: 1.5923 - val_accuracy: 0.5931 - val_loss: 1.5731\n",
      "Epoch 16/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5677 - loss: 1.6007 - val_accuracy: 0.5960 - val_loss: 1.5701\n",
      "Epoch 17/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5674 - loss: 1.5996 - val_accuracy: 0.5989 - val_loss: 1.5704\n",
      "Epoch 18/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: 1.6013 - val_accuracy: 0.5947 - val_loss: 1.5701\n",
      "Epoch 19/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5684 - loss: 1.5999 - val_accuracy: 0.5960 - val_loss: 1.5758\n",
      "Epoch 20/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5538 - loss: 1.6137 - val_accuracy: 0.6009 - val_loss: 1.5680\n",
      "Epoch 21/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5713 - loss: 1.5953 - val_accuracy: 0.5993 - val_loss: 1.5685\n",
      "Epoch 22/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5698 - loss: 1.5976 - val_accuracy: 0.5964 - val_loss: 1.5690\n",
      "Epoch 23/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: 1.6004 - val_accuracy: 0.5898 - val_loss: 1.5728\n",
      "Epoch 24/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 1.6020 - val_accuracy: 0.5865 - val_loss: 1.5753\n",
      "Epoch 25/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5641 - loss: 1.6020 - val_accuracy: 0.5984 - val_loss: 1.5691\n",
      "Epoch 26/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5705 - loss: 1.5959 - val_accuracy: 0.6005 - val_loss: 1.5673\n",
      "Epoch 27/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5640 - loss: 1.6026 - val_accuracy: 0.5968 - val_loss: 1.5699\n",
      "Epoch 28/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5672 - loss: 1.5999 - val_accuracy: 0.5976 - val_loss: 1.5678\n",
      "Epoch 29/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5732 - loss: 1.5951 - val_accuracy: 0.5956 - val_loss: 1.5700\n",
      "Epoch 30/30\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5651 - loss: 1.6003 - val_accuracy: 0.5935 - val_loss: 1.5693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d21e6ce500>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2, \n",
    "          callbacks=keras_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5611 - loss: 1.6013\n",
      "Score: loss of 1.5959843397140503; compile_metrics of 56.82656764984131%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

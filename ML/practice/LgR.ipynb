{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài viết được lấy từ nguồn: [mmlab.uit](https://mmlab.uit.edu.vn/tutorials/ml/gradient-based-model/logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình Logistic Regression\n",
    "\n",
    "**Tổng quan**\n",
    "\n",
    "Logistic Regression được gọi là phân lớp nhị phân - Binary Classification cụ thể mô hình này dùng để dự đoán output dựa vào các giá trị input đã cho. Hầu hết output của Losgistic Regression chỉ có 2 giá trị như: True/False, Yes/No, 0/1,... Một số ví dụ điển hình là phân loại mail có phải spam hay không, phân loại khách hàng có phải tiềm năng hay không.\n",
    "\n",
    "**Ví dụ**\n",
    "\n",
    "Một nhóm 20 sinh viên dành thời gian trong khoảng từ 0 đến 6 giờ cho việc ôn thi. Thời gian ôn thi này ảnh hưởng đến xác suất sinh viên vượt qua kỳ thi như thế nào?\n",
    "\n",
    "| Hours | Pass | Hours | Pass |\n",
    "| ----- | ---- | ----- | ---- |\n",
    "| .5    | 0    | 2.75  | 1    |\n",
    "| .75   | 0    | 3     | 0    |\n",
    "| 1     | 0    | 3.25  | 1    |\n",
    "| 1.25  | 0    | 3.5   | 0    |\n",
    "| 2.25  | 1    | 5     | 1    |\n",
    "| 2.5   | 0    | 5.5   | 1    |\n",
    "\n",
    "Nếu áp dụng  Linear Regression  vào bài toán này, ta  khó có thể đạt kết quả tối ưu (xem hình dưới).\n",
    "\n",
    "![](https://i.imgur.com/LKTj7Uy.png)\n",
    "\n",
    "\n",
    "Do đó chúng ta cần một mô hình phù hợp hơn để giải quyết các bài toán tương tự: Logistic Regression.\n",
    "\n",
    "## Sự giống và khác nhau giữa Linear Regression và Logistic Regression\n",
    "\n",
    "Giống nhau:\n",
    "\n",
    "- Linear Regression và Logistic Regression đều là những mô hình máy học có giám sát.\n",
    "- Đều sử dụng phương trình tuyến tính cho dự đoán.\n",
    "\n",
    "Khác nhau:\n",
    "\n",
    "| Linear Regression                                          | Logistic Regression                                                      |\n",
    "| ---------------------------------------------------------- | ------------------------------------------------------------------------ |\n",
    "| Sử dụng cho các bài toán hồi quy                           | Sử dụng cho các bài toán phân lớp                                        |\n",
    "| Dự đoán giá trị của biến liên tục                          | Dự đoán giá trị của biến rời rạc                                         |\n",
    "| Sử dụng hàm độ lỗi Mean Square Error                       | Sử dụng hàm độ lỗi Cross Entropy                                         |\n",
    "| Mục đích là tìm đường thẳng phù hợp để dự đoán các giá trị | Mục đích là tìm ra đường cong (đường cong sigmoid) để phân biệt các biến |\n",
    "| Đầu ra là các giá trị liên tục                             | Đầu ra là các giá trị trong khoảng (0,1)                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "Nhìn chung Logistic Regression khá giống với Linear Regression đều sử dụng hàm tuyến tính để biểu diễn dữ liệu\n",
    "\n",
    "Hàm tuyến tính: $$ y = 𝑊_1 𝑥_1 + 𝑊_2 𝑥_2 + ... +𝑊_n 𝑥_n + 𝑏$$\n",
    "\n",
    "Tuy nhiên Logistic Regression lại sử dụng thêm hàm sigmoid để chuẩn hoá dữ liệu y về khoảng (0,1)\n",
    "\n",
    "Hàm sigmoid:    $$z = 𝑓(y)=\\frac{1}{1+𝑒^{−y}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính chất hàm số:\n",
    "\n",
    "- Hàm liên tục, cho giá trị trong khoảng (0,1).\n",
    "- Có đạo hàm trên mọi điểm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex\">\n",
    "    <p style=\"position: relative; top:100px; margin-right:90px\">Đồ thị hàm sigmoid</p>\n",
    "    <img src=\"https://i.imgur.com/WCoP88d.png\" style=\"position: relative; margin-top: 20px;heigh:450px;width:450px; margin-bottom:20px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm mất mát - Loss function\n",
    "\n",
    "Hàm mất mát của bài toán sẽ thay đổi tùy thuộc vào ngữ cảnh bài toán\n",
    "\n",
    "**1. Khi bài toán yêu cầu phân loại nhị phân (binary classification)**\n",
    "\n",
    "$$Loss = ∑_{(x,y)\\in D} -y \\log(y') - (1-y) \\log(1-y')$$\n",
    "\n",
    "**1. Khi bài toán yêu cầu phân nhiều lớp (multi-class classification)**\n",
    "\n",
    "$$ Loss = \\frac{1}{n}∑y​ ⋅log(​y') $$\n",
    "\n",
    "Trong đó: \n",
    "- $y$ là các nhãn đã biết trong tập dữ liệu\n",
    "- $y'$ là nhãn mà chúng ta dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triển khai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv('Bank_Personal_Loan_Modelling.csv')\n",
    "\n",
    "X = np.array([0.5, 0.75, 1, 1.25, 1.5, 1.75, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4, 4.25, 4.5, 4.75, 5, 5.5])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3. Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Initialize sigmoid**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Initialize Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    # Clip predictions to avoid log(0) error\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Initialize parameter**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 #learning late\n",
    "W = np.random.uniform(0,1) # colom 1\n",
    "b = 0.1\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Run model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_epochs):\n",
    "    z = np.dot(X_train, W) + b\n",
    "    y_pred = sigmoid(z)\n",
    "    # print(cross_entropy_loss(predict(X_train, W, b), y_train))\n",
    "    gradient_W = np.dot((y_pred-y_train).T, X_train)/X_train.shape[0]\n",
    "    gradient_b = np.mean(y_pred-y_train)\n",
    "    W = W - lr * gradient_W\n",
    "    b = b - lr* gradient_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Predict**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    z = np.dot(X, W) + b\n",
    "    z = sigmoid(z)\n",
    "    y_pred = [int(i > 0.5) for i in z]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.8\n",
      "Train: 0.75\n",
      "data: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print('Test:', f1_score(predict(X_test, W, b), y_test))\n",
    "print('Train:', f1_score(predict(X_train, W, b), y_train))\n",
    "print('data:', f1_score(predict(X, W, b), y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

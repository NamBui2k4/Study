{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: \n",
    "\n",
    "+ [geeksforgeeks](https://www.geeksforgeeks.org/k-nearest-neighbours/)\n",
    "+ [viblo](https://viblo.asia/p/distance-measure-trong-machine-learning-ByEZkopYZQ0)\n",
    "\n",
    "# K-Nearest Neighbor(KNN) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is one of the most basic yet essential classification algorithms in machine learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining, and intrusion detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is widely used in real-life scenarios since it is non-parametric.\n",
    "\n",
    "This means that we don't have to make any assumption about distribution of data (unlike GMM, which assume a Gaussian distribution of the given data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ease of implementation\n",
    "- no need for assumptions about data distribution\n",
    "- Be able to handle both numerical and categorical data\n",
    "- non-parametric, means that the predictions base on the similarity of data points\n",
    "- less sensitive to outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Suppose we have training data set D which has been classified into 2 labels (+) and (-).\n",
    "\n",
    "Then, we have a new data point A with unknown labels. \n",
    "\n",
    "So how can we determine whether A's label is (+) or (-)?\n",
    "\n",
    "![](https://images.viblo.asia/full/7fc8b286-3585-4404-933d-e253892d80e4.png)\n",
    "\n",
    "The simplest way is to compare all the features of A with all features of labeled data points to see which one is most similar.\n",
    "\n",
    "+ If the features of A are similar to the features of (+) data,  then A is labeled (+) \n",
    "+ If the features of A are similar to the features of (-) data,  then it is labeled (-)\n",
    " \n",
    "It looks very simple but that is what KNN does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, The K-NN works by finding the K nearest neighbors to new data point.\n",
    "\n",
    "This coud be performed by mathematical calculation to measure the distance between the new data and all the points in the training data set D.\n",
    "\n",
    "The distance calculation between 2 points can be Euclidian, Manhattan, weighted, Minkowski, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Euclidean Distance\n",
    "\n",
    "Perhaps this is the most popular method because everyone has had to learn it since middle school. Euclidean Distance is also known as\n",
    "L2 distance.\n",
    "\n",
    "<div style=\"display:space-between; margin-left:130px; margin-top: 30px\">\n",
    "    <img src=\"https://images.viblo.asia/fa91897f-5864-4ad5-9861-426ba195852a.png\" > \n",
    "    <img src=\"https://images.viblo.asia/full/5964d828-bd19-41d6-940b-49de91baf4a4.png\" style=\"margin-left:130px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formular:\n",
    "\n",
    "$$D(x,y)= \\sqrt{∑^n_{i=1}​ (x_i​ −y_i​ )^2}$$\n",
    " \n",
    "In which: \n",
    " +  $x = (x_1,x_2,...,x_n) $\n",
    " +  $y = (y_1,y_2,...,y_n) $\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "- Popular, easy to understand, easy to implement, good results in many use cases\n",
    "- Especially effective with low-dimensional data,\n",
    "\n",
    "cons:\n",
    "\n",
    "- Euclidean distance can be affected by the unit of the feature. Therefore, it is necessary to normalize before calculating\n",
    "- The second problem is that as the number of vector space dimensions increases, Euclidean Distance becomes less effective. Part of the reason is that real data often does not lie only in Euclidean Metric Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manhattan Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as L1 distance (or Taxicab/City Block distance)\n",
    "\n",
    "Manhattan Distance is generally used when we are interested in the total distance traveled by the object instead of the displacement. This metric is calculated by summing the absolute difference between the coordinates of the points in n-dimensions.\n",
    "\n",
    "Formular:\n",
    "\n",
    "$$D(x,y)= ∑^k_{i=1}​ ∣x_i​ − y_i​∣$$\n",
    "\n",
    "In which:\n",
    " +  $x = (x_1,x_2,...,x_n) $\n",
    " +  $y = (y_1,y_2,...,y_n) $\n",
    "\n",
    "\n",
    "<div style=\"display:space-between; margin-left:230px; margin-top: 50px\"> \n",
    "    <img src=\"https://images.viblo.asia/full/64f82926-3a2a-4dbc-9bb8-05582c4c0d10.png\" style=\"margin-left:130px\">\n",
    "</div>\n",
    "\n",
    " \n",
    "### Example \n",
    "\n",
    "Consider this picture below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.viblo.asia/full/a269be93-a5e3-4d13-a1f5-da2a83c787d1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be understood that on the map: \n",
    "- Euclide Distance is the way the crow flies (blue) \n",
    "- Manhattan is the road (red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other example:\n",
    "\n",
    "![](https://diendantoanhoc.org/uploads/monthly_04_2021/post-182654-0-33441000-1617727019.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another variation of Manhattan Distance is Canberra distance\n",
    "\n",
    "$$D(x,y)= ∑^n_{i=1}​\\frac{∣x_i​ − y_i​∣}{ ∣x_i​∣ + ∣y_i​∣ }$$\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chebyshev Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chebyshev distance is simpler to calculate, calculating the maximum deviation of two vectors along the coordinate axis. Also known as Chessboard distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D(x,y)= max​ (∣x_i​ − y_i​ ∣)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:space-between; margin-left:230px; margin-top: 50px\"> \n",
    "    <img src=\"https://images.viblo.asia/full/88defc46-4263-409a-bbcf-54810a1f390a.png\" style=\"margin-left:30px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "\n",
    "<img src=\"https://images.viblo.asia/5727900a-439e-40e9-bbd4-f15a17b1e1b8.png\" style=\"heigh:320px;width:320px;margin-left:70px\">\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

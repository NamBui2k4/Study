{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài viết này được xây dựng từ nguồn: [Quy's blog](https://ndquy.github.io/posts/cac-phuong-phap-scaling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phương pháp Scaling dữ liệu\n",
    "\n",
    "Trong machine learning, một điều quan trọng khi training mô hình bằng dataset chính là việc scaling dữ liệu. Vậy thì Scaling dữ liệu là gì ? \n",
    "\n",
    "Dữ liệu trong dataset thường rất đa dạng về đơn vị đo đạc (m và feet chẳng hạn), hoặc là các thuộc tính của chúng khác nhau về miền giá trị rất rất nhiều. Ví dụ, dữ liệu của một công dân sẽ có (ít nhất) 2 thuộc tính là chiều cao và cân nặng. Trong khi cân nặng có thể rơi vào khoảng 60 - 80 thì chiều cao chỉ rơi vào khoảng 15 - 20. Đó là một sự chênh lệch rất khủng khiếp, chưa kể đó mới chỉ là 2 thuộc tính thôi và đơn vị còn khác nhau nữa. \n",
    "\n",
    "Trong thực tế, dữ liệu tồn tại dưới dạng vector với rất nhiều thuộc tính, và tất nhiên là đơn vị mỗi thuộc tính cũng khác nhau và miền giá trị khác nhau. Nhưng máy tính thì lại không thể xử lý chúng trực tiếp như vậy. Do đó, phương pháp Scaling dữ liệu được ra đời để giải quyết bài toán này.\n",
    "\n",
    "Training mô hình là một chuyện, nhưng mô hình có chất lượng hay không sẽ được quyết định bởi việc Scaling\n",
    "\n",
    "**Có 2 cách để Scaling:**\n",
    "-  normalization \n",
    "-  standardization.\n",
    "\n",
    "**Các đối tượng cần Scaling:**\n",
    "\n",
    "1. Dữ liệu đầu vào\n",
    "\n",
    "Chúng ta luôn có nguyên tắc sau\n",
    "\n",
    "***Nguyên tắc:*** \n",
    "\n",
    "  + Dữ liệu đầu vào phải có giá trị nhỏ, có thể nằm trong khoảng (0, 1) hoặc được chuẩn hóa với giá trị trung bình bằng 0 và độ lệch chuẩn bằng 1. \n",
    "\n",
    "\n",
    "  + Nếu phân phối của dữ liệu là phân phối chuẩn thì chúng nên được standardization, nếu không thì nên được normalization. Điều này áp dụng khi phạm vi giá trị lớn (10, 100…) hoặc nhỏ (0.01, 0.0001).\n",
    "\n",
    "  + Nếu giá trị của biến nhỏ (gần trong khoảng 0-1) và phân phối bị giới hạn (ví dụ độ lệch chuẩn gần với 1) thì chúng ta không cần phải scale dữ liệu.\n",
    "  \n",
    "Đây là 3 nguyên tắc được đúc kết nhằm đảm bảo mô hình được training chất lượng. Và để triển khai chúng, việc lý tưởng nhất chính là Scaling dữ liệu đầu vào\n",
    "\n",
    "2. Dữ liệu đầu ra\n",
    "\n",
    "Chúng ta cần đảm bảo dữ liệu đầu ra khớp với miền giá trị mà mô hình sẽ chấp nhận. \n",
    "\n",
    "Nếu đầu vào của mô hình thuộc miền (0, 1) thì đầu ra cũng nên thuộc miền này. Tuy nhiên, vấn đề là nằm ở việc chọn mô hình sao cho hợp lý chứ không phải tìm mọi cách để \"ép buộc\" đầu ra rơi vào miền (0, 1)\n",
    "\n",
    "Ví dụ nếu bài toán của bạn là regression thì đầu ra sẽ là một giá trị số thực. Mô hình tốt nhất cho bài toán này đó là lựa chọn các hàm tuyến tính ($ax+by+cz+...= y$). Nếu đầu ra có phân phối chuẩn thì chúng ta có thể standardize đầu ra. Nếu không thì normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization - bình thường hóa dữ liệu\n",
    "\n",
    "Cụm từ \"bình thường hóa dữ liệu\" xuất phát từ quan điểm rằng dữ liệu sau khi được biến đổi sẽ có dạng \"bình thường\" hơn, nghĩa là nó sẽ tuân theo phân phối chuẩn.\n",
    "\n",
    "Normalization là phương pháp scale dữ liệu từ miền giá trị bất kì sang miền giá trị nằm trong khoảng 0 đến 1.\n",
    "\n",
    "**Công thức:**\n",
    "\n",
    "$$X_{std}​ = \\frac{X- X_{min}}{X_{max} −X_{min}}​$$\n",
    "\n",
    "$$X_{scaled}​ = X_{std}​ ⋅(max−min)+min$$\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- X là dữ liệu ban đầu.\n",
    "- $X_{min}$​ và $X_{max}$​ là giá trị tối thiểu và tối đa của dữ liệu.\n",
    "- $min$ và $max$ là khoảng giá trị mong muốn (thường là $[0, 1]$).\n",
    "\n",
    "Phương pháp này yêu cầu chúng ta cần xác định được giá trị lớn nhất ($X_{max}$) và giá trị nhỏ nhất ($X_{min}$) của dữ liệu.\n",
    "\n",
    "Nếu dữ liệu đầu vào nằm ngoài phạm vi $X_{min}$ và $X_{max}$ thì đầu ra sẽ không nằm trong phạm vi (0, 1). Đó được gọi là dữ liệu ngoại lai (Outlier).\n",
    "\n",
    "***Đọc thêm [Outlier là gì](Outlier.ipynb)***\n",
    "\n",
    "Để normalize dữ liệu, ta cần normalize từng thuộc tính (feature) của dữ liệu. Công thức trên áp dụng đối với từng feature.\n",
    "\n",
    "**Ví dụ:** \n",
    "\n",
    "Xét tập data sau:\n",
    "```python\n",
    "    [-1,   2]\n",
    "    [-0.5, 6] \n",
    "    [0,    10]\n",
    "    [1,    18]\n",
    "```\n",
    "Đây là một ma trận có 2 cột, mỗi cột là một feature. \n",
    "\n",
    "Xét feature `[-1, -0.5, 0 ,1]`. Khi đó, $X_{min} = -1 $ và $X_{max} = 1$.\n",
    "\n",
    "Vì ta mong muốn Scaling về khoản (0, 1) nên $max = 1$, $min = 0$.\n",
    "\n",
    "- Với X = -1, \n",
    "  + $X_{std}​ = \\frac{-1 - (-1)}{1 - (-1)}​ = 0$, \n",
    "  + $X_{scaled}​ = X_{std}​ (max−min)+min = 0.$\n",
    "\n",
    "Tương tự:\n",
    "\n",
    "- Với X = -0.5, \n",
    "  + $X_{std}​ = \\frac{-0.5 - (-1)}{1 - (-1)}​ = 0.25$\n",
    "  + $X_{scaled}​ = X_{std}​ (max − min) + min = 0.25$\n",
    "  \n",
    "- Với X = 0,\n",
    "  + $X_{std}​ = \\frac{0 - (-1)}{1 - (-1)} = 0.5$\n",
    "  + $X_{scaled}​ = X_{std}​ (max - min) + min = 0.5$\n",
    "\n",
    "- Với X = 1,\n",
    "  + $X_{std}​ = \\frac{1 - (-1)}{1 - (-1)} = 1$\n",
    "  + $X_{scaled}​ = X_{std}​ (max - min) + min = 1$\n",
    "\n",
    "Vậy là ta có feature mới sau khi Scaling là `[0. , 0.25, 0.5, 1.]`\n",
    "\n",
    "Áp dụng tương tự, cho feature tiếp theo, ta được: `[0. , 0.25, 0.5, 1]`\n",
    "\n",
    "Như vậy kết quả sau khi Scaling là:\n",
    "\n",
    "```python\n",
    "[0.  0. ]\n",
    "[0.25 0.25]\n",
    "[0.5 0.5 ]\n",
    "[1.  1. ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thực hiện normalize dữ liệu bằng MinMaxScaler trong thư viện scikit-learn.\n",
    "\n",
    "MinMaxScaler là một lớp trong thư viện scikit-learn của Python được sử dụng để normalize dữ liệu\n",
    "\n",
    "MinMaxScaler có 2 phương thức quan trọng: `fit()` và `transform()`\n",
    "\n",
    "- `fit()`: Xác định giá trị tối thiểu và tối đa của mỗi feature trong dataset\n",
    "- `transform()`: Áp dụng công thức trên cho từng feature \n",
    "\n",
    "MinMaxScaler mặc định sẽ đưa dữ liệu về miền giá trị [0, 1]\n",
    "**Ví dụ sử dụng MinMaxScaler:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 18.]\n",
      "[-1.  2.]\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[-1,   2], \n",
    "        [-0.5, 6], \n",
    "        [0,    10], \n",
    "        [1,    18]]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "# Biến đổi dữ liệu\n",
    "transformed_data = scaler.transform(data)\n",
    "print(transformed_data)\n",
    "\n",
    "# Output:\n",
    "# [[0.   0.  ]\n",
    "#  [0.25 0.25]\n",
    "#  [0.5  0.5 ]\n",
    "#  [1.   1.  ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng tham số `feature_range` để đưa vào giá trị min và max nếu bạn muốn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để đảo ngược miền giá trị sau khi scale về miền giá trị gốc giúp thuận tiện cho việc báo cáo hay vẽ biểu đồ, bạn có thể gọi hàm `inverse_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.   2. ]\n",
      " [-0.5  6. ]\n",
      " [ 0.  10. ]\n",
      " [ 1.  18. ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [[-1,   2], \n",
    "        [-0.5, 6], \n",
    "        [0,    10], \n",
    "        [1,    18]]\n",
    "\n",
    "# fit scaler vào data\n",
    "scaler.fit(data)\n",
    "\n",
    "# Thực hiện scale\n",
    "normalized = scaler.transform(data)\n",
    "\n",
    "# quay lại miền giá trị cũ\n",
    "inverse = scaler.inverse_transform(normalized)\n",
    "\n",
    "# Output\n",
    "print(inverse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
